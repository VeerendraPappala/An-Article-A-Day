# An-Article-A-Day

## Day-1 | Build Book Recommender Systems. 


![book-shelf](https://user-images.githubusercontent.com/45025357/52583901-b168a080-2e56-11e9-8ab2-511ace369f80.jpg)

  **Article Is about Building Recommendation System for Books using Booksdata Set.** 
  
* Virtually everyone has had an online experience where a website makes personalized recommendations. Amazon tells you “Customers Who Bought This Item Also Bought”, Udemy tells you “Students Who Viewed This Course Also Viewed”. Building recommender systems today requires specialized expertise in analytics, machine learning and software engineering, and learning new skills and tools is difficult and time-consuming.
* So, if you want to learn how to build a recommender system from scratch, Read  the complete article from [here](https://towardsdatascience.com/how-did-we-build-book-recommender-systems-in-an-hour-part-2-k-nearest-neighbors-and-matrix-c04b3c2ef55c)  
* Checkout the code from here -  [DAY1](https://github.com/VeerendraPappala/BOOK-RECOMMENDATION-SYSTEM/blob/master/Books_Recommendation.ipynb)


## Day-2 | Summarize Trump’s State of the Union Address

![trump](https://user-images.githubusercontent.com/45025357/52652831-d3c0f380-2f14-11e9-887b-a564feaee770.jpg)

**Article Is about build a Text summarizer so as to summarize Trumps reactions on State of White Houses instead of listening entire speech for  82minutes** 

* Automatic text summarization, is the process of creating a short, concise and coherent version of a longer document
 
* Read the complete [Article](https://towardsdatascience.com/automatically-summarize-trumps-state-of-the-union-address-6757c6af6534)

* Checkout the code from here - [Day2](https://github.com/VeerendraPappala/Analyise-Summarize-Trump-s-remarks-on-state-of-the-Union-Houses/blob/master/Summarize-Trump's-Remarks.ipynb)

## Day-3 | Time Forecast using  Tpot Automated ML in python

![tpot-logo](https://user-images.githubusercontent.com/45025357/52727507-5f9d5300-2fdb-11e9-99b7-d86acc80f44a.jpg)

**Article is about Time Forecast Using TPOT- An automated Machine Learning In Python**

* TPOT is meant to be an assistant that gives you ideas on how to solve a particular machine learning problem by exploring pipeline configurations that you might have never considered, then leaves the fine-tuning to more constrained parameter tuning techniques such as grid search.

* So TPOT helps you find good algorithms. Note that it isn’t designed for automating deep learning — something like AutoKeras might be helpful there.
* AutoML algorithms aren’t as simple as fitting one model on the dataset; they are considering multiple machine learning algorithms (random forests, linear models, SVMs, etc.) in a pipeline with multiple preprocessing steps (missing value imputation, scaling, PCA, feature selection, etc.), the hyperparameters for all of the models and preprocessing steps, as well as multiple ways to ensemble or stack the algorithms within the pipeline.

* There are so many interesting directions to explore with TPOT and autoML. I’d like to compare TPOT with autoSKlearn, MLBox, Auto-Keras, and others. I’d also like to see how it performs with a greater variety of data, other imputation strategies, and other encoding strategies. A comparison with LightGBM, CatBoost , and deep learning algorithms would also be interesting. 

* For More info info Read the complete [Article](https://towardsdatascience.com/time-forecast-with-tpot-b2d87eaba59c) & [Documentation](http://epistasislab.github.io/tpot/using/)

* Checkout the complete Code here - [Day3](https://github.com/VeerendraPappala/Time-Forecast-Using-TPOT/blob/master/TPOT.ipynb)

## Day-4 | PYTORCH AND ResNet for Traffic Sign Classification With PyTorch

![pytorch-logo](https://user-images.githubusercontent.com/45025357/52785901-36360300-307f-11e9-97f4-d01c619a51ab.jpg)

**Article is Restnet used  with pytorch to classify German Traffic Board signs using Fastai in Python** 

* PyTorch was one of the most popular frameworks in 2018.PyTorch is a Python based scientific computing package that is similar to NumPy, but with the added power of GPUs. It is also a deep learning framework that provides maximum flexibility and speed during implementing and building deep neural network architectures.

* The FastAi library is a high level library build on PyTorch, which allows us to build models using only a few lines of code.The FastAI library provides a lot of different datasets which can be loaded in directly, but it also provides functionality for downloading images given a file containing the urls of these images.

* Fastai  allows us to perform transfer learning with less code and time by giving us the ability to set different learning rates for different parts in the network. This allows us to train the earlier layers less than the latter layers.

* Get here  more Info on [pytorch official Guide](https://pytorch.org/tutorials/), 
[Deep Learning with PyTorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
,[ Introduction on pytorch](https://www.analyticsvidhya.com/blog/2019/01/guide-pytorch-neural-networks-case-studies/),  [Resnet for traffic signs Classification using Pytorch](https://towardsdatascience.com/resnet-for-traffic-sign-classification-with-pytorch-5883a97bbaa3)

* Code for - [Day4](https://github.com/VeerendraPappala/PYTORCH/blob/master/Resnet.ipynb)

## Day-5 | Google Facets & Bookeh For Data Visualisation in Python

![data-visualization-tools-in-python-15-638](https://user-images.githubusercontent.com/45025357/52860670-1b828d80-3156-11e9-98f1-b0b950b93ae8.jpg)

**Visualising Machine Learning Datasets with Google’s FACETS - An open source tool from Google to easily learn patterns from large amounts of data And Bokeh**

* Data visualization is important to create meaningful information and decision making power. Data is useless if its not creating any meaning. I did  EDA with FACETS on the universal Dataset and Heart Disease dataset from Kaggle. 
* more info is here 
  * [Article on Facets](https://towardsdatascience.com/visualising-machine-learning-datasets-with-googles-facets-462d923251b3)            
  * [Article on Bokeh](https://towardsdatascience.com/interactive-plotting-with-bokeh-ea40ab10870)
  * [Documentation on Bokeh](https://bokeh.pydata.org/en/latest/docs/user_guide/layout.html)
  * [Facets](https://ai.googleblog.com/2017/07/facets-open-source-visualization-tool.html)
  
* Notebooks of Day-5 - [Facets](https://github.com/VeerendraPappala/Data-Visualization/tree/master/FACETS) & [Bokeh](https://github.com/bokeh/bokeh-notebooks/tree/master/tutorial)



## Day-6 | Develop a NLP Model in Python & Deploy It with Flask
![flask](https://user-images.githubusercontent.com/45025357/52902710-9a50f680-323a-11e9-92ea-49942e0b974b.png)

**In reality, generating predictions is only part of a machine learning project, although it is the most important part . This article is about how to deploying a model in Production using Flask.**

* For more info, chekout these articles
  * [Tutorial to deploy Machine Learning models in Production as APIs](https://www.analyticsvidhya.com/blog/2017/09/machine-learning-models-as-apis-using-flask/)
  * [Deploying a Machine Learning Model as a REST API](https://towardsdatascience.com/deploying-a-machine-learning-model-as-a-rest-api-4a03b865c166)
  * [NLP model Deployement Using Flask](https://towardsdatascience.com/develop-a-nlp-model-in-python-deploy-it-with-flask-step-by-step-744f3bdd7776)
  
* The complete working source code is available at this repository - [Day-6](https://github.com/susanli2016/SMS-Message-Spam-Detector) 
 









